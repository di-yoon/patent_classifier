import os, glob, streamlit as st
from dotenv import load_dotenv
from methods.finetuning.client import FineTuningInference
from utils import excel_download
from utils.db_utils import init_infer_db, save_inference_results

load_dotenv()
def show():
    with st.expander("**COLUMN TO USE FOR INFERENCE**", expanded=True):

        df = st.session_state.uploaded_df

        #  í•˜ë‚˜ì˜ ì»¬ëŸ¼ë§Œ ì„ íƒ
        selected_col = st.selectbox(
            "SELECT COLUMN",
            options=df.columns.tolist(),
            index=df.columns.get_loc("ëŒ€í‘œì²­êµ¬í•­") if "ëŒ€í‘œì²­êµ¬í•­" in df.columns else 0,
            key="inference_col"
        )

    with st.expander("**MODEL TO USE FOR INFERENCE**", expanded=False):

        model_selection_method = st.radio(
            "MODEL SELECTION METHOD",
            ["AUTOMATIC SEARCH", "MANUAL PATH ENTRY"],
            key="model_selection_method"
        )

        if model_selection_method == "MANUAL PATH ENTRY":
            model_path = st.text_input(
                "ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
                value=r"C:\company\wips\excel_gemma_2_2b\merged_model",
                help="í•™ìŠµ ì™„ë£Œ í›„ ìƒì„±ëœ model í´ë”ì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”."
            )
        else:
            base_dir = r"C:\company\wips"

            if os.path.exists(base_dir):
                try:
                    # merged_model í´ë” ê²€ìƒ‰
                    merged_model_paths = glob.glob(os.path.join(base_dir, "*", "merged_model"))

                    valid_models = []
                    for merged_path in merged_model_paths:
                        # config.json ë˜ëŠ” pytorch_model.bin íŒŒì¼ ì¡´ì¬ í™•ì¸
                        if (os.path.exists(os.path.join(merged_path, 'config.json')) or
                                os.path.exists(os.path.join(merged_path, 'pytorch_model.bin')) or
                                os.path.exists(os.path.join(merged_path, 'model.safetensors'))):
                            # ìƒìœ„ í´ë” ì´ë¦„ìœ¼ë¡œ í‘œì‹œ
                            parent_dir = os.path.basename(os.path.dirname(merged_path))
                            valid_models.append((parent_dir, merged_path))

                    if valid_models:
                        # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì´ë¦„ê³¼ ì‹¤ì œ ê²½ë¡œ ë¶„ë¦¬
                        model_names = [name for name, path in valid_models]
                        selected_model_name = st.selectbox(
                            "ê²€ìƒ‰ëœ ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                            options=model_names
                        )

                        # ì„ íƒëœ ëª¨ë¸ì˜ ì‹¤ì œ ê²½ë¡œ ì°¾ê¸°
                        model_path = next(path for name, path in valid_models if name == selected_model_name)

                        st.info(f"ì„ íƒëœ ëª¨ë¸ ê²½ë¡œ: {model_path}")
                    else:
                        st.warning("No merged model could be found using automatic search.")
                        model_path = st.text_input(
                            "ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
                            value=r"C:\company\wips\excel_gemma_2_2b\merged_model"
                        )
                except Exception as e:
                    st.error(f"ëª¨ë¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    model_path = st.text_input(
                        "ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
                        value=r"C:\company\wips\excel_gemma_2_2b\merged_model"
                    )
            else:
                st.error(f"The default directory does not exist. : {base_dir}")
                model_path = st.text_input(
                    "ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
                    value=r"C:\company\wips\excel_gemma_2_2b\merged_model"
                )

        model_exists = False

        if model_path and os.path.exists(model_path):
            # ë³‘í•© ëª¨ë¸ íŒŒì¼ë“¤ ì¡´ì¬ í™•ì¸
            config_exists = os.path.exists(os.path.join(model_path, 'config.json'))
            model_file_exists = (os.path.exists(os.path.join(model_path, 'pytorch_model.bin')) or
                                 os.path.exists(os.path.join(model_path, 'model.safetensors')))

            if config_exists and model_file_exists:
                model_exists = True
                st.success("ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                # ë¼ë²¨ ì •ë³´ í‘œì‹œ (ìƒìœ„ í´ë”ì—ì„œ í™•ì¸)
                parent_dir = os.path.dirname(model_path)
                label_file_path = os.path.join(parent_dir, 'label_mappings.pkl')

                if os.path.exists(label_file_path):
                    try:
                        import pickle
                        with open(label_file_path, 'rb') as f:
                            mappings = pickle.load(f)
                            model_labels = mappings['labels_list']

                            with st.expander("**LABELS FOR THE TRAINED MODEL**", expanded=False):
                                st.write(sorted(model_labels))

                    except Exception as e:
                        st.warning(f"ë¼ë²¨ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                else:
                    st.warning("ë¼ë²¨ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì§€ì •ëœ ê²½ë¡œì— ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    #  ì¶”ë¡  ì‹¤í–‰
    if st.button("**I N F E R E N C E**", type="primary", width='stretch', disabled=not model_exists):
        try:
            model_name = st.session_state.get('ft_model_name', 'google/gemma-2-2b')
            hf_token = st.session_state.get('ft_hf_token') or os.getenv('HF_TOKEN')

            inference = FineTuningInference(model_name, hf_token)

            with st.spinner("LOADING MERGED MODEL ..."):
                inference.load_model(model_path, is_merged_model=True)

            with st.spinner("RUNNING INFERENCE ..."):
                results_df = inference.predict_patents(
                    df, model_path,
                    selected_cols=selected_col
                )

            st.toast("INFERENCE IS COMPLETE")

            st.subheader("INFERENCE RESULT (Raw)")
            st.dataframe(results_df, width='stretch')

            # ğŸ” ê²°ê³¼ í•„í„°ë§ UI
            with st.expander("ğŸ” ê²°ê³¼ í•„í„°ë§", expanded=True):
                unique_labels = results_df["ì˜ˆì¸¡_ë¼ë²¨"].unique().tolist() if "ì˜ˆì¸¡_ë¼ë²¨" in results_df.columns else []
                selected_labels = st.multiselect("ë¼ë²¨ ì„ íƒ", unique_labels, default=unique_labels)

                conf_min, conf_max = 0.0, 1.0
                if "ì‹ ë¢°ë„" in results_df.columns:
                    conf_range = st.slider("ì‹ ë¢°ë„ ë²”ìœ„", 0.0, 1.0, (0.0, 1.0), step=0.05)
                    conf_min, conf_max = conf_range

                search_id = st.text_input("ì¶œì›ë²ˆí˜¸ ê²€ìƒ‰", "")

            # === í•„í„° ì ìš© ===
            filtered = results_df.copy()
            if selected_labels:
                filtered = filtered[filtered["ì˜ˆì¸¡_ë¼ë²¨"].isin(selected_labels)]
            if "ì‹ ë¢°ë„" in filtered.columns:
                filtered = filtered[(filtered["ì‹ ë¢°ë„"] >= conf_min) & (filtered["ì‹ ë¢°ë„"] <= conf_max)]
            if search_id:
                filtered = filtered[filtered["ì¶œì›ë²ˆí˜¸"].astype(str).str.contains(search_id)]

            # ê²°ê³¼ í…Œì´ë¸”
            st.subheader("FILTERED RESULT")
            st.dataframe(filtered, width='stretch')

            # ë¶„í¬ ì°¨íŠ¸
            if "ì˜ˆì¸¡_ë¼ë²¨" in filtered.columns:
                st.subheader("PREDICTION DISTRIBUTION (Filtered)")
                st.bar_chart(filtered["ì˜ˆì¸¡_ë¼ë²¨"].value_counts())

            st.session_state.inference_results = results_df
            excel_download.show_finetuning(results_df)

            init_infer_db()
            save_inference_results(model_name, selected_col, results_df)
            st.success("ì¶”ë¡  ê²°ê³¼ê°€ SQLite DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.code(str(e))
